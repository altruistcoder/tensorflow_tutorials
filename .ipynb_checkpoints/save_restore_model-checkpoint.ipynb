{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and restore models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model progress can be saved during—and after—training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\n",
    "\n",
    "- code to create the model, and\n",
    "- the trained weights, or parameters, for the model <br>\n",
    "\n",
    "Sharing this data helps others understand how the model works and try it themselves with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 14s 1us/step\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
      "  159  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
      "  252 237   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
      "  233 252  57   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
      "   84 252 253 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
      "   96 189 253 167   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "   47  79 255 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
      "    0   0 253 243  50   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
      "    0   0 253 252 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
      "    0   0 255 253 196   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
      "    0   0 253 252 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
      "    7 135 253 186  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
      "  131 252 225  71   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      "  252 173   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
      "   56   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.2         0.62352941  0.99215686  0.62352941  0.19607843\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.18823529  0.93333333  0.98823529  0.98823529  0.98823529\n",
      "  0.92941176  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.21176471  0.89019608  0.99215686  0.98823529  0.9372549\n",
      "  0.91372549  0.98823529  0.22352941  0.02352941  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.03921569  0.23529412  0.87843137  0.98823529  0.99215686  0.98823529\n",
      "  0.79215686  0.32941176  0.98823529  0.99215686  0.47843137  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.63921569  0.98823529  0.98823529  0.98823529  0.99215686\n",
      "  0.98823529  0.98823529  0.37647059  0.74117647  0.99215686  0.65490196\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.2         0.93333333  0.99215686  0.99215686\n",
      "  0.74509804  0.44705882  0.99215686  0.89411765  0.18431373  0.30980392\n",
      "  1.          0.65882353  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.18823529  0.93333333  0.98823529\n",
      "  0.98823529  0.70196078  0.04705882  0.29411765  0.4745098   0.08235294\n",
      "  0.          0.          0.99215686  0.95294118  0.19607843  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.14901961  0.64705882\n",
      "  0.99215686  0.91372549  0.81568627  0.32941176  0.          0.          0.\n",
      "  0.          0.          0.          0.99215686  0.98823529  0.64705882\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.02745098\n",
      "  0.69803922  0.98823529  0.94117647  0.27843137  0.0745098   0.10980392\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.99215686  0.98823529  0.76470588  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.22352941  0.98823529  0.98823529  0.24705882  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.99215686  0.98823529  0.76470588  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.77647059  0.99215686  0.74509804  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  1.          0.99215686  0.76862745  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.29803922  0.96470588  0.98823529  0.43921569  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.99215686  0.98823529  0.58039216  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.33333333  0.98823529  0.90196078  0.09803922  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.02745098\n",
      "  0.52941176  0.99215686  0.72941176  0.04705882  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.33333333  0.98823529  0.8745098   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.02745098\n",
      "  0.51372549  0.98823529  0.88235294  0.27843137  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.33333333  0.98823529  0.56862745  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18823529\n",
      "  0.64705882  0.98823529  0.67843137  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.3372549   0.99215686  0.88235294\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.44705882  0.93333333  0.99215686  0.63529412  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.33333333\n",
      "  0.98823529  0.97647059  0.57254902  0.18823529  0.11372549  0.33333333\n",
      "  0.69803922  0.88235294  0.99215686  0.8745098   0.65490196  0.21960784\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.33333333  0.98823529  0.98823529  0.98823529  0.89803922\n",
      "  0.84313725  0.98823529  0.98823529  0.98823529  0.76862745  0.50980392\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.10980392  0.78039216  0.98823529\n",
      "  0.98823529  0.99215686  0.98823529  0.98823529  0.91372549  0.56862745\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.09803922  0.50196078  0.98823529  0.99215686  0.98823529  0.55294118\n",
      "  0.14509804  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "print(train_images[1])\n",
    "train_images = train_images[:1000].reshape(-1, 28*28)/255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28*28)/255.0\n",
    "\n",
    "print(train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "  \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoints during training\n",
    "The primary use case is to automatically save checkpoints during and at the end of training. This way you can use a trained model without having to retrain it, or pick-up training where you left of—in case the training process was interrupted.\n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint is a callback that performs this task. The callback takes a couple of arguments to configure checkpointing.\n",
    "\n",
    "### Checkpoint callback usage\n",
    "Train the model and pass it the ModelCheckpoint callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 948us/step - loss: 1.1742 - acc: 0.6530 - val_loss: 0.7451 - val_acc: 0.7610\n",
      "\n",
      "Epoch 00001: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 318us/step - loss: 0.4243 - acc: 0.8840 - val_loss: 0.5357 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00002: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 361us/step - loss: 0.2958 - acc: 0.9230 - val_loss: 0.4687 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00003: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 452us/step - loss: 0.2179 - acc: 0.9400 - val_loss: 0.4428 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00004: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 325us/step - loss: 0.1571 - acc: 0.9630 - val_loss: 0.4102 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00005: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 339us/step - loss: 0.1182 - acc: 0.9800 - val_loss: 0.4015 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00006: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 327us/step - loss: 0.0883 - acc: 0.9890 - val_loss: 0.4108 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00007: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 427us/step - loss: 0.0723 - acc: 0.9930 - val_loss: 0.4110 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00008: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 357us/step - loss: 0.0513 - acc: 0.9960 - val_loss: 0.4071 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00009: saving model to save_restore_model/train_1/cp.ckpt\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 337us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.4076 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00010: saving model to save_restore_model/train_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d20beae10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'train_1/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Creating checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), \n",
    "         callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new, untrained model. When restoring a model from only weights, you must have a model with the same architecture as the original model. Since it's the same model architecture, we can share weights despite that it's a different instance of the model.\n",
    "\n",
    "Now rebuild a fresh, untrained model, and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 104us/step\n",
      "Untrained model, accuracy: 10.30%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels,)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the weights from checkpoint and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 43us/step\n",
      "Restored model, accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss, acc = model.evaluate(test_images, test_labels,)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint callback options\n",
    "The callback provides several options to give the resulting checkpoints unique names, and adjust the checkpointing frequency.\n",
    "\n",
    "Train a new model, and save uniquely named checkpoints once every 5-epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to train_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to train_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to train_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to train_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to train_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to train_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to train_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to train_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to train_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to train_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d2252ed68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'train_2/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True, period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=50, validation_data=(test_images, test_labels), \n",
    "         callbacks=[cp_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('train_2/cp-0030.ckpt'),\n",
       " PosixPath('train_2/cp-0035.ckpt'),\n",
       " PosixPath('train_2/cp-0040.ckpt'),\n",
       " PosixPath('train_2/cp-0045.ckpt'),\n",
       " PosixPath('train_2/cp-0050.ckpt')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the checkpoints by modification time.\n",
    "checkpoints = pathlib.Path(checkpoint_dir).glob(\"*.index\")\n",
    "checkpoints = sorted(checkpoints, key=lambda cp:cp.stat().st_mtime)\n",
    "checkpoints = [cp.with_suffix('') for cp in checkpoints]\n",
    "latest = str(checkpoints[-1])\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 86us/step\n",
      "Restored model, accuracy: 87.70%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually save weights\n",
    "Above you saw how to load the weights into a model.\n",
    "\n",
    "Manually saving the weights is just as simple, use the Model.save_weights method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 93us/step\n",
      "Restored model, accuracy: 87.70%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Restore the weights\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the entire model\n",
    "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allows you to checkpoint a model and resume training later—from the exact same state—without access to the original code.\n",
    "\n",
    "Saving a fully-functional model in Keras is very useful—you can load them in TensorFlow.js and then train and run them in web browsers.\n",
    "\n",
    "Keras provides a basic save format using the HDF5 standard. For our purposes, the saved model can be treated as a single binary blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 1.1639 - acc: 0.6570\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 313us/step - loss: 0.4089 - acc: 0.8900\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 303us/step - loss: 0.2867 - acc: 0.9230\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 287us/step - loss: 0.2035 - acc: 0.9470\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 281us/step - loss: 0.1574 - acc: 0.9620\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including weights and optimizer.\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 142us/step\n",
      "Restored model, accuracy: 86.30%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique saves everything:\n",
    "\n",
    "- The weight values\n",
    "- The model's configuration(architecture)\n",
    "- The optimizer configuration\n",
    "\n",
    "Keras saves models by inspecting the architecture. Currently, it is not able to save TensorFlow optimizers (from tf.train). When using those you will need to re-compile the model after loading, and you will loose the state of the optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLenv]",
   "language": "python",
   "name": "conda-env-MLenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
